<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Tracing the Representation Geometry of Language Models from Pretraining to Post-training - Li et al.">
  <meta name="description" content="We uncover a consistent non-monotonic sequence of three geometric phases during LLM pretraining through spectral analysis of representation geometry using RankMe and Î±-ReQ metrics.">
  <meta name="keywords" content="language models, representation geometry, pretraining, post-training, spectral analysis, RankMe, eigenspectrum, OLMo, Pythia, machine learning, deep learning">
  <meta name="author" content="Melody Zixuan Li, Kumar Krishna Agrawal, Arna Ghosh, Komal Kumar Teru, Adam Santoro, Guillaume Lajoie, Blake A. Richards">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Mila - Quebec AI Institute & McGill University">
  <meta property="og:title" content="Tracing the Representation Geometry of Language Models from Pretraining to Post-training">
  <meta property="og:description" content="We uncover a consistent non-monotonic sequence of three geometric phases during LLM pretraining through spectral analysis of representation geometry using RankMe and Î±-ReQ metrics.">
  <meta property="og:url" content="https://melodylizx.github.io/llm-geometry-project/">
  <meta property="og:image" content="https://melodylizx.github.io/llm-geometry-project/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Tracing the Representation Geometry of Language Models - Research Preview">
  <meta property="article:published_time" content="2025-09-27T00:00:00.000Z">
  <meta property="article:author" content="Melody Zixuan Li">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="language models">
  <meta property="article:tag" content="representation geometry">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@kumarkagrawal">
  <meta name="twitter:creator" content="@kumarkagrawal">
  <meta name="twitter:title" content="Tracing the Representation Geometry of Language Models from Pretraining to Post-training">
  <meta name="twitter:description" content="We uncover a consistent non-monotonic sequence of three geometric phases during LLM pretraining through spectral analysis of representation geometry using RankMe and Î±-ReQ metrics.">
  <meta name="twitter:image" content="https://melodylizx.github.io/llm-geometry-project/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Tracing the Representation Geometry of Language Models - Research Preview">
  <meta name="twitter:url" content="https://x.com/kumarkagrawal/status/1983977646620078398">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Tracing the Representation Geometry of Language Models from Pretraining to Post-training">
  <meta name="citation_author" content="Li, Melody Zixuan">
  <meta name="citation_author" content="Agrawal, Kumar Krishna">
  <meta name="citation_author" content="Ghosh, Arna">
  <meta name="citation_author" content="Teru, Komal Kumar">
  <meta name="citation_author" content="Santoro, Adam">
  <meta name="citation_author" content="Lajoie, Guillaume">
  <meta name="citation_author" content="Richards, Blake A.">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="NeurIPS 2025">
  <meta name="citation_pdf_url" content="https://arxiv.org/pdf/2509.23024.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <title>Tracing the Representation Geometry of Language Models from Pretraining to Post-training - Li et al. | Academic Research</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Custom Styles for Enhanced Features -->
  <style>
    /* Dark Mode Variables */
    :root {
      --bg-primary: #ffffff;
      --bg-secondary: #f5f5f5;
      --text-primary: #363636;
      --text-secondary: #666;
      --border-color: #dbdbdb;
      --shadow: rgba(0,0,0,0.1);
      --shadow-hover: rgba(0,0,0,0.15);
    }
    
    body.dark-mode {
      --bg-primary: #1a1a1a;
      --bg-secondary: #2d2d2d;
      --text-primary: #e0e0e0;
      --text-secondary: #b0b0b0;
      --border-color: #404040;
      --shadow: rgba(0,0,0,0.3);
      --shadow-hover: rgba(0,0,0,0.5);
    }
    
    body.dark-mode {
      background-color: var(--bg-primary);
      color: var(--text-primary);
      transition: background-color 0.3s, color 0.3s;
    }
    
    body.dark-mode .hero.is-light {
      background-color: var(--bg-secondary) !important;
    }
    
    body.dark-mode .section, 
    body.dark-mode .hero-body {
      background-color: var(--bg-primary);
    }
    
    body.dark-mode .title,
    body.dark-mode .subtitle {
      color: var(--text-primary) !important;
    }
    
    body.dark-mode .content {
      color: var(--text-primary);
    }
    
    body.dark-mode .sticky-nav {
      background: rgba(26, 26, 26, 0.98);
    }
    
    body.dark-mode .sticky-nav .nav-title,
    body.dark-mode .sticky-nav .nav-links a {
      color: var(--text-primary);
    }
    
    body.dark-mode footer {
      background-color: var(--bg-secondary) !important;
    }

    /* Dark Mode Toggle Button */
    .dark-mode-toggle {
      position: fixed;
      top: 20px;
      right: 20px;
      z-index: 1001;
      background: var(--bg-primary);
      border: 2px solid var(--border-color);
      border-radius: 50%;
      width: 50px;
      height: 50px;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      box-shadow: 0 4px 10px var(--shadow);
      transition: all 0.3s ease;
    }
    
    .dark-mode-toggle:hover {
      transform: scale(1.1);
      box-shadow: 0 6px 15px var(--shadow-hover);
    }
    
    .dark-mode-toggle i {
      font-size: 1.5rem;
      color: var(--text-primary);
    }

    /* Smaller figure captions */
    .subtitle {
      font-size: 0.85rem !important;
      color: var(--text-secondary);
      line-height: 1.4;
    }
    
    /* Smaller affiliation font */
    .publication-authors {
      font-size: 0.95rem !important;
    }
    
    .publication-authors .author-block {
      font-size: 0.9rem !important;
    }
    
    .publication-authors .eql-cntrb {
      font-size: 0.85rem !important;
    }

    /* Sticky Navigation */
    .sticky-nav {
      position: fixed;
      top: 0;
      left: 0;
      right: 0;
      background: rgba(255, 255, 255, 0.95);
      backdrop-filter: blur(12px);
      box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
      z-index: 1000;
      padding: 12px 0;
      transform: translateY(-100%);
      transition: transform 0.35s ease, background 0.3s ease, box-shadow 0.3s ease;
      will-change: transform;
    }
    
    .sticky-nav.visible {
      transform: translateY(0);
    }
    
    .sticky-nav .nav-content {
      display: flex;
      justify-content: space-between;
      align-items: center;
      max-width: 1200px;
      margin: 0 auto;
      padding: 0 24px;
    }
    
    .sticky-nav .nav-title {
      font-weight: 700;
      font-size: 1rem;
      color: #222;
      flex: 1;
      white-space: nowrap;
      overflow: hidden;
      text-overflow: ellipsis;
      max-width: 400px;
    }
    
    .sticky-nav .nav-links {
      display: flex;
      gap: 24px;
      align-items: center;
    }
    
    .sticky-nav .nav-links a {
      color: #333;
      text-decoration: none;
      font-weight: 500;
      font-size: 0.9rem;
      transition: color 0.2s ease;
    }
    
    .sticky-nav .nav-links a:hover {
      color: #3273dc;
    }

    /* Lightbox for Figures */
    .lightbox-overlay {
      display: none;
      position: fixed;
      inset: 0;
      background: rgba(0, 0, 0, 0.9);
      z-index: 2000;
      cursor: zoom-out;
      animation: fadeIn 0.3s ease;
    }

    .lightbox-overlay.active {
      display: flex;
      justify-content: center;
      align-items: center;
      padding: 20px;
    }

    .lightbox-content {
      max-width: 95%;
      max-height: 95%;
      object-fit: contain;
      animation: zoomIn 0.3s ease;
    }

    .lightbox-close {
      position: absolute;
      top: 20px;
      right: 30px;
      color: white;
      font-size: 36px;
      font-weight: bold;
      cursor: pointer;
      z-index: 2001;
      transition: color 0.2s;
    }

    .lightbox-close:hover {
      color: #ccc;
    }

    .clickable-figure {
      cursor: zoom-in;
      transition: transform 0.25s ease, box-shadow 0.25s ease;
    }

    .clickable-figure:hover {
      transform: scale(1.03);
      box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);
    }

    @keyframes fadeIn {
      from { opacity: 0; }
      to { opacity: 1; }
    }

    @keyframes zoomIn {
      from { transform: scale(0.85); opacity: 0; }
      to { transform: scale(1); opacity: 1; }
    }
    
    /* Scroll to top button */
    .scroll-to-top {
      position: fixed;
      bottom: 30px;
      right: 30px;
      z-index: 1000;
      background: var(--bg-primary);
      border: 2px solid var(--border-color);
      border-radius: 50%;
      width: 50px;
      height: 50px;
      display: none;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      box-shadow: 0 4px 10px var(--shadow);
      transition: all 0.3s ease;
    }
    
    .scroll-to-top:hover {
      transform: scale(1.1);
      box-shadow: 0 6px 15px var(--shadow-hover);
    }
    
    .scroll-to-top i {
      font-size: 1.2rem;
      color: var(--text-primary);
    }
    
    /* Responsive adjustments */
    @media screen and (max-width: 768px) {
      .sticky-nav .nav-title {
        font-size: 0.85rem;
        max-width: 200px;
      }
      
      .sticky-nav .nav-links {
        gap: 10px;
      }
      
      .sticky-nav .nav-links a {
        font-size: 0.8rem;
      }
      
      .dark-mode-toggle {
        width: 45px;
        height: 45px;
        top: 15px;
        right: 15px;
      }
    }
  </style>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Tracing the Representation Geometry of Language Models from Pretraining to Post-training",
    "description": "Standard training metrics like loss fail to explain the emergence of complex capabilities in large language models. We take a spectral approach to investigate the geometry of learned representations across pretraining and post-training, measuring effective rank (RankMe) and eigenspectrum decay (Î±-ReQ).",
    "author": [
      {
        "@type": "Person",
        "name": "Melody Zixuan Li",
        "affiliation": {
          "@type": "Organization",
          "name": "McGill University & Mila - Quebec AI Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Kumar Krishna Agrawal",
        "affiliation": {
          "@type": "Organization",
          "name": "UC Berkeley"
        }
      },
      {
        "@type": "Person",
        "name": "Arna Ghosh",
        "affiliation": {
          "@type": "Organization",
          "name": "McGill University & Mila - Quebec AI Institute"
        }
      },
      {
        "@type": "Person",
        "name": "Komal Kumar Teru",
        "affiliation": {
          "@type": "Organization",
          "name": "Cohere"
        }
      },
      {
        "@type": "Person",
        "name": "Adam Santoro",
        "affiliation": {
          "@type": "Organization",
          "name": "Google Deepmind"
        }
      },
      {
        "@type": "Person",
        "name": "Guillaume Lajoie",
        "affiliation": {
          "@type": "Organization",
          "name": "Mila - Quebec AI Institute & UniversitÃ© de MontrÃ©al"
        }
      },
      {
        "@type": "Person",
        "name": "Blake A. Richards",
        "affiliation": {
          "@type": "Organization",
          "name": "Mila - Quebec AI Institute & McGill University"
        }
      }
    ],
    "datePublished": "2025-09-27",
    "publisher": {
      "@type": "Organization",
      "name": "NeurIPS 2025"
    },
    "url": "https://melodylizx.github.io/llm-geometry-project/",
    "image": "https://melodylizx.github.io/llm-geometry-project/static/images/social_preview.png",
    "keywords": ["language models", "representation geometry", "pretraining", "spectral analysis", "RankMe", "eigenspectrum"],
    "abstract": "Standard training metrics like loss fail to explain the emergence of complex capabilities in large language models. We take a spectral approach to investigate the geometry of learned representations across pretraining and post-training, measuring effective rank (RankMe) and eigenspectrum decay (Î±-ReQ). With OLMo (1B-7B) and Pythia (160M-12B) models, we uncover a consistent non-monotonic sequence of three geometric phases during autoregressive pretraining.",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "about": [
      {
        "@type": "Thing",
        "name": "Language Models"
      },
      {
        "@type": "Thing", 
        "name": "Representation Learning"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Mila - Quebec AI Institute",
    "url": "https://mila.quebec",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico"
  }
  </script>
</head>
<body>

  <!-- Dark Mode Toggle -->
  <button class="dark-mode-toggle" onclick="toggleDarkMode()" title="Toggle Dark Mode" aria-label="Toggle Dark Mode">
    <i class="fas fa-moon" id="darkModeIcon"></i>
  </button>

  <!-- Sticky Navigation -->
  <nav class="sticky-nav" id="stickyNav">
    <div class="nav-content">
      <div class="nav-title">LLM Representation Geometry | NeurIPS 2025</div>
      <div class="nav-links">
        <a href="#abstract">Abstract</a>
        <a href="#method">Method</a>
        <a href="#findings">Findings</a>
        <a href="#BibTeX">Paper</a>
      </div>
    </div>
  </nav>

  <!-- Lightbox Overlay for Images -->
  <div class="lightbox-overlay" id="lightbox" onclick="closeLightbox()">
    <span class="lightbox-close" onclick="closeLightbox()">&times;</span>
    <img class="lightbox-content" id="lightboxImg">
  </div>

  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Tracing the Representation Geometry of Language Models from Pretraining to Post-training</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://melodylizx.github.io/" target="_blank">Melody Zixuan Li</a><sup>1,2,*</sup>,</span>
              <span class="author-block">
                <a href="https://people.eecs.berkeley.edu/~krishna/" target="_blank">Kumar Krishna Agrawal</a><sup>3,*</sup>,</span>
              <span class="author-block">
                <a href="https://arnaghosh.github.io/" target="_blank">Arna Ghosh</a><sup>1,2,9,*</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=ZkxLTT4AAAAJ&hl=en" target="_blank">Komal Kumar Teru</a><sup>4</sup>,</span>
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=evIkDWoAAAAJ&hl=en" target="_blank">Adam Santoro</a><sup>5,â€ </sup>,</span>
              <span class="author-block">
                <a href="https://guillaumelajoie.com/" target="_blank">Guillaume Lajoie</a><sup>2,6,9</sup>,</span>
              <span class="author-block">
                <a href="https://sites.google.com/mila.quebec/linc-lab/team/blake?authuser=0" target="_blank">Blake A. Richards</a><sup>1,2,7,8,9</sup>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Computer Science, McGill University</span>
              <span class="author-block"><sup>2</sup>Mila - Quebec AI Institute</span>
              <span class="author-block"><sup>3</sup>UC Berkeley</span>
              <span class="author-block"><sup>4</sup>Cohere</span>
              <span class="author-block"><sup>5</sup>Google Deepmind</span><br>
              <span class="author-block"><sup>6</sup>Mathematics and Statistics, UniversitÃ© de MontrÃ©al</span>
              <span class="author-block"><sup>7</sup>Neurology & Neurosurgery and Montreal Neurological Institute, McGill University</span><br>
              <span class="author-block"><sup>8</sup>CIFAR Learning in Machines & Brains Program</span>
              <span class="author-block"><sup>9</sup>Google, Paradigms of Intelligence Team</span><br>
              <span class="eql-cntrb"><small><sup>*</sup>Equal contribution</small></span>
              <span class="eql-cntrb"><small><sup>â€ </sup>Advisory capacity only</small></span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">NeurIPS 2025</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2509.23024.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code - update with your GitHub repository URL when available -->
              <span class="link-block">
                <a href="https://github.com/YOUR_REPO_HERE" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code (Coming Soon)</span>
              </a>
            </span>

            <span class="link-block">
              <a href="https://arxiv.org/abs/2509.23024" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="ai ai-arxiv"></i>
              </span>
              <span>arXiv</span>
            </a>
          </span>
        </div>
      </div>
    </div>
  </div>
</div>
</div>
</section>


<!-- Teaser video/image section -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- Replace with your teaser figure/video -->
      <img src="static/images/figure0.jpg" alt="Three geometric phases of LLM pretraining" class="clickable-figure" onclick="openLightbox(this.src)" style="width:100%">
      <h2 class="subtitle has-text-centered">
        We discover three distinct geometric phases during language model pretraining: warmup (representational collapse), entropy-seeking (dimensionality expansion with peak n-gram memorization), and compression-seeking (anisotropic consolidation leading to improved downstream performance).
      </h2>
    </div>
  </div>
</section>
<!-- End teaser -->

<!-- Paper abstract -->
<section class="section hero is-light" id="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Standard training metrics like loss fail to explain the emergence of complex capabilities in large language models. We take a spectral approach to investigate the geometry of learned representations across pretraining and post-training, measuring effective rank (RankMe) and eigenspectrum decay (Î±-ReQ). 
          </p>
          <p>
            With OLMo (1B-7B) and Pythia (160M-12B) models, we uncover a consistent non-monotonic sequence of three geometric phases during autoregressive pretraining. The initial "warmup" phase exhibits rapid representational collapse. This is followed by an "entropy-seeking" phase, where the manifold's dimensionality expands substantially, coinciding with peak n-gram memorization. Subsequently, a "compression-seeking" phase imposes anisotropic consolidation, selectively preserving variance along dominant eigendirections while contracting others, a transition marked with significant improvement in downstream task performance.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method Overview -->
<section class="section hero is-light" id="method">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="content has-text-justified">
          <p>
            We primarily consider the final layer, last token activations as the representations for a given input sequence and study the geometry of the corresponding manifold. To analyze the intrinsic geometry of the manifold, we compute the feature covariance matrix.
          </p>
          <p>
            We analyze the representation geometry of language models during training using two complementary spectral metrics:
          </p>
          <ul>
            <li><strong>RankMe (Effective Rank):</strong> Measures the effective dimensionality of the representation manifold</li>
            <li><strong>Î±-ReQ (Eigenspectrum Decay):</strong> Quantifies how quickly eigenvalues decay, indicating anisotropic structure</li>
          </ul>
          <p>
            We apply these metrics to study OLMo (1B-7B parameters) and Pythia (160M-12B parameters) models across their full pretraining trajectories and post-training phases.
          </p>
        </div>
      </div>
    </div>
    <!-- Method Figure 1 -->
    <div class="columns is-centered has-text-centered" style="margin-top: 30px;">
      <div class="column is-four-fifths">
        <img src="static/images/figure1.jpeg" alt="Method visualization" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:100%; margin: 20px auto;">
        <p class="subtitle"><strong>Figure 1:</strong> Spectral framework reveals three universal phases in LLM training. (A) LLM representations analyzed via empirical feature covariance Î£Ì‚(f<sub>Î¸</sub>) of last-token hidden states f<sub>Î¸</sub>(x<sub>i</sub>). (B) Two complementary spectral metrics: Î±-ReQ measures eigenspectrum decay rate (variance concentration), while RankMe quantifies effective rank (utilized dimensionality).</p>
      </div>
    </div>
  </div>
</section>

<!-- Key Findings Section -->
<section class="hero is-small" id="findings">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Key Findings</h2>
      
      <!-- Quick Navigation -->
      <div class="content has-text-centered" style="margin-bottom: 40px; padding: 20px; background-color: #f5f5f5; border-radius: 8px;">
        <p style="margin-bottom: 15px; font-weight: 600; color: #363636;"></p>
        <div style="display: flex; flex-wrap: wrap; justify-content: center; gap: 10px;">
          <a href="#finding1" class="button is-small is-link is-light">ðŸ”„ Three Geometric Phases</a>
          <a href="#finding2" class="button is-small is-link is-light">ðŸ“Š Memorization vs Generalization</a>
          <a href="#finding3" class="button is-small is-link is-light">ðŸŽ¯ Post-training Analysis</a>
          <a href="#finding4" class="button is-small is-link is-light">ðŸ”¬ Why These Phases Arise</a>
          <a href="#finding5" class="button is-small is-link is-light">ðŸ’¡ Spectral Tail Information</a>
        </div>
      </div>
      
      <!-- Finding 1: Three Geometric Phases -->
      <div id="finding1" class="content" style="margin-bottom: 50px; scroll-margin-top: 80px;">
        <h3 class="title is-4">ðŸ”„ Three Geometric Phases</h3>
        <div class="content has-text-justified">
          <p>
            We find that while the pretraining loss decreases monotonically, the spectral changes are non-monotonic! In particular, we find that LLMs undergo 3 distinct phases during pretraining:
          </p>
          <ul>
            <li><strong>Warmup:</strong> Rapid compression which collapses representation to dominant directions</li>
            <li><strong>Entropy-seeking:</strong> Manifold expansion, adding information in non-dominant directions</li>
            <li><strong>Compression-seeking:</strong> Anisotropic consolidation, selectively packing more information in dominant directions</li>
          </ul>
        </div>
        <div class="content has-text-centered" style="margin-top: 30px;">
          <img src="static/images/figure2.jpeg" alt="Three geometric phases" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:90%; margin: 20px auto;">
          <p class="subtitle"><strong>Figure 2:</strong> Loss decreases monotonically, but representation geometry does not. (A) Schematic from Fig 1, for the pretraining stage. (B) Cross-entropy loss, gradient norm and learning rate schedule during OLMo-2 7B model pretraining. (C, D) RankMe and Î±-ReQ, respectively, for OLMo-2 7B model vary non-monotonically across pretraining, demonstrating three key phases: "warmup", "entropy-seeking", and "compression-seeking". (E, F) Same as C,D, but for Pythia models, demonstrating the consistent existence of the three phases across model families and scales.</p>
        </div>
      </div>

      <!-- Finding 2: Memorization vs Generalization -->
      <div id="finding2" class="content" style="margin-bottom: 50px; scroll-margin-top: 80px;">
        <h3 class="title is-4">ðŸ“Š Memorization vs Generalization Across Phases</h3>
        <div class="content has-text-justified">
          <p>
            Does the representation complexity inform us about changes in LLM behavior? To understand this better, we investigate LLM behavior from the lens of memorization vs generalization across the different phases.
          </p>
          <p>
            Strikingly, we find that the model uses characteristically different mechanisms as it optimizes the next-token prediction objective:
          </p>
          <ul>
            <li><strong>Entropy-seeking phase:</strong> Correlates with short-sequence memorization, as measured using n-gram alignment</li>
            <li><strong>Compression-seeking phase:</strong> Correlates with dramatic gains in factual reasoning requiring long-range dependencies (e.g., TriviaQA)</li>
          </ul>
        </div>
        <div class="content has-text-centered" style="margin-top: 30px;">
          <img src="static/images/figure3.jpeg" alt="Memorization vs generalization" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:90%; margin: 20px auto;">
          <p class="subtitle"><strong>Figure 3:</strong> Distinct learning phases are linked to different LLM capabilities. (A) Memorization metric, i.e. spearman correlation between LLM and âˆž-gram outputs, and representation geometry metric, Î±-ReQ, across Pythia models' (1â€“12B parameters) pretraining. Memorization peaks late in the "entropy-seeking" phase before plateauing or degrading slightly in the "compression-seeking" phase, suggesting that the former prioritizes capturing short-context n-gram statistics. (B) 0-shot performance on multiple-choice (SciQ) and factual question-answering (TriviaQA) tasks across pretraining. While accuracy on SciQ benefits from learning in both phases, accuracy on TriviaQA groks once the model learns long-context statistics, primarily in the "compression-seeking" phase.</p>
        </div>
      </div>

      <!-- Finding 3: Post-training -->
      <div id="finding3" class="content" style="margin-bottom: 50px; scroll-margin-top: 80px;">
        <h3 class="title is-4">ðŸŽ¯ Post-training: SFT/DPO vs RLVR</h3>
        <div class="content has-text-justified">
          <p>
            Post training: we find key differences between SFT/DPO and RLVR:
          </p>
          <ul>
            <li><strong>SFT & DPO</strong> exhibit entropy-seeking expansion, favoring instruction memorization but reducing OOD robustness</li>
            <li><strong>RLVR</strong> exhibits compression-seeking consolidation, learning reward-aligned behaviors at the cost of reduced exploration</li>
          </ul>
          <p>
            We believe this rank-consolidation helps explain why base models can recover better performance at high pass@K compared to RLVR-tuned models.
          </p>
        </div>
        <div class="content has-text-centered" style="margin-top: 30px;">
          <img src="static/images/figure4.jpeg" alt="Post-training comparison" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:90%; margin: 20px auto;">
          <p class="subtitle"><strong>Figure 4:</strong> Post-training induces distinct geometric transformations in model representations, aligned with specific behavioral changes. (A) Conceptual overview of post-training (SFT, DPO and RLVR) (top), corresponding RankMe metrics from intermediate checkpoints of Llama-3.1-TÃ¼lu-3.1-8B (bottom) highlighting distinct progression for each stage. (B) Impact of pretraining on OLMo-2-1B SFT (Anthropic-HH): (top) longer pretraining improves in-distribution (ID) performance, while out-of-distribution (OOD) generalization (Alpaca farm) saturates (bottom) Overtrained models with higher RankMe exhibit markedly distinct outputs on AlpacaEval after undergoing SFT on two different datasets (Anthropic-HH and Alpaca farm). (C) RLVR post-training narrows base model's (Llama-3.1-8B-TÃ¼lu-3-DPO) exploratory behavior on AMC-23 (particularly at higher sampling counts e.g. k = 256), suggesting higher effective-rank facilitates better search.</p>
        </div>
      </div>

      <!-- Finding 4: Why do these phases arise? -->
      <div id="finding4" class="content" style="margin-bottom: 50px; scroll-margin-top: 80px;">
        <h3 class="title is-4">ðŸ”¬ Why Do These Geometric Phases Arise?</h3>
        <div class="content has-text-justified">
          <p>
            We show, both analytically and with simulations in a toy model, that gradient descent dynamics with cross-entropy loss, coupled with skewed token frequencies and representation bottlenecks, are the key reasons underlying these non-monotonic spectral changes.
          </p>
        </div>
        <div class="content has-text-centered" style="margin-top: 30px;">
          <img src="static/images/figure5.gif" alt="Toy model simulation" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:90%; margin: 20px auto;">
          <p class="subtitle"><strong>Figure 5:</strong> Learning dynamics of cross-entropy loss replicate multiphase learning dynamics. (A) Schematic of a model with feature extractor f<sub>Î¸</sub> (âˆˆ R<sup>d</sup>), linear classifier W (âˆˆ R<sup>nÃ—d</sup>) and cross-entropy loss â„’<sub>CE</sub>. Skewed class distribution and information bottleneck (d < n) are critical to replicate all three phases observed in LLM pretraining. (B, C) Classifier weights (W<sub>i</sub>) and feature representations (f<sub>Î¸</sub>(x)) demonstrate distinctive trajectories analogous to "warmup" (dotted), "entropy-seeking" (solid), and "compression-seeking" (dashed) phases. (D) Quantitative spectral metrics RankMe and eigenvalues, Ïƒ<sub>1</sub>, Ïƒ<sub>2</sub>.</p>
        </div>
      </div>

      <!-- Finding 5: Task-relevant information in eigendirections -->
      <div id="finding5" class="content" style="margin-bottom: 50px; scroll-margin-top: 80px;">
        <h3 class="title is-4">ðŸ’¡ Task-Relevant Information in Spectral Tail</h3>
        <div class="content has-text-justified">
          <p>
            Is task-relevant info contained in the top eigendirections? To understand this we project the activations to a top-K / bottom-K subspaces and measure performance on standard benchmarks.
          </p>
          <p>
            Surprisingly, we find that in line with our theoretical results, the spectral tail encodes critical task-relevant information, while the dominant directions are expendable for many tasks!
          </p>
          <p>
            In particular, on SciQ:
          </p>
          <ul>
            <li>Removing top 50 directions barely hurts accuracy</li>
            <li>Retaining only top 50 directions collapses performance</li>
          </ul>
        </div>
        <div class="content has-text-centered" style="margin-top: 30px;">
          <img src="static/images/figure6.png" alt="Eigendirection analysis table" class="clickable-figure" onclick="openLightbox(this.src)" style="max-width:90%; margin: 20px auto;">
          <p class="subtitle"><strong>Table 1:</strong> Full-spectrum information is required. Retaining only top eigen-directions markedly degrades SciQ accuracy.</p>
        </div>
      </div>

    </div>
  </div>
</section>


<!-- Video presentation (if available) -->
<!-- Uncomment and update when you have a video
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/YOUR_VIDEO_ID" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
-->

<!-- Poster (if available) -->
<!-- Uncomment and update when you have a poster
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>
      <iframe src="static/pdfs/poster.pdf" width="100%" height="550"></iframe>
    </div>
  </div>
</section>
-->

<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <div class="bibtex-header">
      <h2 class="title">BibTeX</h2>
      <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
        <i class="fas fa-copy"></i>
        <span class="copy-text">Copy</span>
      </button>
    </div>
    <pre id="bibtex-code"><code>@inproceedings{li2025tracing,
  title={Tracing the Representation Geometry of Language Models from Pretraining to Post-training},
  author={Li, Melody Zixuan and Agrawal, Kumar Krishna and Ghosh, Arna and Teru, Komal Kumar and Santoro, Adam and Lajoie, Guillaume and Richards, Blake A.},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  year={2025},
  url={https://arxiv.org/abs/2509.23024}
}</code></pre>
  </div>
</section>
<!--End BibTex citation -->

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
<!-- End of Statcounter Code -->

<!-- Custom JavaScript for Enhanced Features -->
<script>
  // Dark Mode Toggle
  function toggleDarkMode() {
    const body = document.body;
    const icon = document.getElementById('darkModeIcon');
    
    body.classList.toggle('dark-mode');
    
    // Update icon
    if (body.classList.contains('dark-mode')) {
      icon.classList.remove('fa-moon');
      icon.classList.add('fa-sun');
      localStorage.setItem('darkMode', 'enabled');
    } else {
      icon.classList.remove('fa-sun');
      icon.classList.add('fa-moon');
      localStorage.setItem('darkMode', 'disabled');
    }
  }
  
  // Check for saved dark mode preference on page load
  document.addEventListener('DOMContentLoaded', function() {
    const darkMode = localStorage.getItem('darkMode');
    const icon = document.getElementById('darkModeIcon');
    
    if (darkMode === 'enabled') {
      document.body.classList.add('dark-mode');
      icon.classList.remove('fa-moon');
      icon.classList.add('fa-sun');
    }
  });
  
  // Sticky Navigation
  window.addEventListener('scroll', function() {
    const nav = document.getElementById('stickyNav');
    if (window.scrollY > 300) {
      nav.classList.add('visible');
    } else {
      nav.classList.remove('visible');
    }
  });
  
  // Lightbox Functions
  function openLightbox(src) {
    const lightbox = document.getElementById('lightbox');
    const lightboxImg = document.getElementById('lightboxImg');
    lightboxImg.src = src;
    lightbox.classList.add('active');
    document.body.style.overflow = 'hidden'; // Prevent background scrolling
  }
  
  function closeLightbox() {
    const lightbox = document.getElementById('lightbox');
    lightbox.classList.remove('active');
    document.body.style.overflow = 'auto'; // Re-enable scrolling
  }
  
  // Close lightbox on Escape key
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape') {
      closeLightbox();
    }
  });
  
  // Smooth scroll to sections
  function scrollToSection(sectionId) {
    const element = document.getElementById(sectionId);
    if (element) {
      element.scrollIntoView({ behavior: 'smooth', block: 'start' });
    }
  }
  
  // Smooth scroll for all anchor links
  document.querySelectorAll('a[href^="#"]').forEach(anchor => {
    anchor.addEventListener('click', function (e) {
      e.preventDefault();
      const target = document.querySelector(this.getAttribute('href'));
      if (target) {
        target.scrollIntoView({ behavior: 'smooth', block: 'start' });
      }
    });
  });
  
  // Copy BibTeX function
  function copyBibTeX() {
    const bibtexCode = document.getElementById('bibtex-code');
    const textArea = document.createElement('textarea');
    textArea.value = bibtexCode.textContent;
    document.body.appendChild(textArea);
    textArea.select();
    document.execCommand('copy');
    document.body.removeChild(textArea);
    
    // Visual feedback
    const copyBtn = document.querySelector('.copy-bibtex-btn');
    const originalText = copyBtn.innerHTML;
    copyBtn.innerHTML = '<i class="fas fa-check"></i> <span class="copy-text">Copied!</span>';
    copyBtn.style.background = '#48c774';
    
    setTimeout(() => {
      copyBtn.innerHTML = originalText;
      copyBtn.style.background = '';
    }, 2000);
  }
  
  // Scroll to top function
  function scrollToTop() {
    window.scrollTo({
      top: 0,
      behavior: 'smooth'
    });
  }
  
  // Show/hide scroll to top button based on scroll position
  window.addEventListener('scroll', function() {
    const scrollBtn = document.querySelector('.scroll-to-top');
    if (scrollBtn) {
      if (window.scrollY > 500) {
        scrollBtn.style.display = 'flex';
      } else {
        scrollBtn.style.display = 'none';
      }
    }
  });
</script>

</body>
</html>
